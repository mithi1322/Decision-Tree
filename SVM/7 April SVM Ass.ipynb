{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb71be09-6253-49d0-8388-bf66fd098b33",
   "metadata": {},
   "source": [
    "Q1. What is the relationship between polynomial functions and kernel functions in machine learning algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bda2f5b-2cb0-4f14-a4a4-bb3a5cfe5e8d",
   "metadata": {},
   "source": [
    "# Answer 1:\n",
    "In machine learning algorithms, polynomial functions are often used as kernel functions in kernel-based methods such as Support Vector Machines (SVMs). A kernel function defines the similarity or distance measure between pairs of samples in a higher-dimensional feature space without explicitly computing the transformation to that space. Polynomial kernels are a specific type of kernel function that compute the similarity or distance based on polynomial transformations.\n",
    "\n",
    "Polynomial kernel functions use the polynomial equation to map the input data into a higher-dimensional space, where the linear separation of samples might be possible. The degree parameter in the polynomial kernel determines the degree of the polynomial transformation. For example, a quadratic kernel has a degree of 2, a cubic kernel has a degree of 3, and so on.\n",
    "\n",
    "The relationship between polynomial functions and kernel functions lies in the fact that polynomial kernels allow SVMs to effectively handle non-linear classification problems by implicitly mapping the data into a higher-dimensional space using polynomial transformations. This approach provides a powerful mechanism to capture complex patterns and relationships in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591b30b4-425c-4cc4-899b-1732b700e9b4",
   "metadata": {},
   "source": [
    "Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee274f05-82f8-4fbc-b06a-5315e5aadfd3",
   "metadata": {},
   "source": [
    "# Answer 2:\n",
    "In Python, you can implement an SVM with a polynomial kernel using the Scikit-learn library. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc780b1d-92ba-4d32-adc7-e4776d998049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an instance of the SVM classifier with a polynomial kernel\n",
    "svm_model = SVC(kernel='poly', degree=3)\n",
    "\n",
    "# Train the SVM classifier on the training data\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the testing data\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the SVM model using accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4fac4c-387b-4940-ac7b-d9c090e59fa0",
   "metadata": {},
   "source": [
    "Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c8eb6c-3ff2-4237-9655-0b07005e3b3f",
   "metadata": {},
   "source": [
    "# Answer 3:\n",
    "In Support Vector Regression (SVR), epsilon (ε) is a parameter that controls the width of the margin around the predicted regression function. It defines a tube around the function within which errors are considered acceptable. Increasing the value of epsilon allows for a larger tube, meaning that samples within this tube are not considered errors and do not contribute to the support vectors.\n",
    "\n",
    "As epsilon increases, the number of support vectors typically decreases. This is because a larger tube allows more samples to be correctly predicted within the margin, reducing the need for additional support vectors. Consequently, increasing epsilon tends to result in a sparser model with fewer support vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe109778-d9e7-432b-a308-7c5aeca08f6b",
   "metadata": {},
   "source": [
    "Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330597eb-b17e-4fae-af4e-a27bc704300c",
   "metadata": {},
   "source": [
    "# Answer 4:\n",
    "Kernel Function: The choice of kernel function determines the mapping of the input data to a higher-dimensional feature space. Different kernel functions have different properties and can capture different types of relationships in the data. For example, the linear kernel assumes a linear relationship, while the RBF kernel can capture non-linear relationships. The choice of kernel depends on the problem at hand and the underlying data distribution.\n",
    "\n",
    "C Parameter: The C parameter controls the trade-off between model complexity and training error. It determines the penalty for misclassifying training samples. A smaller C value leads to a larger margin and a simpler model, while a larger C value allows for a smaller margin and potentially better fit to the training data. Increasing C may result in a more complex model that could be prone to overfitting, while decreasing C may lead to underfitting.\n",
    "\n",
    "Epsilon (ε) Parameter: In SVR, epsilon determines the width of the tube around the regression function within which errors are considered acceptable. A larger epsilon allows for a larger tube, which may increase the number of support vectors and result in a more robust model to noise. Smaller epsilon values make the model more sensitive to errors and may lead to a smaller number of support vectors.\n",
    "\n",
    "Gamma Parameter: The gamma parameter controls the influence of individual training samples on the regression. It defines the width of the RBF kernel and influences the smoothness of the decision function. A smaller gamma value leads to a wider kernel and smoother decision boundaries, while a larger gamma value results in a narrower kernel and more complex decision boundaries. Increasing gamma can make the model more prone to overfitting, while decreasing gamma can result in underfitting.\n",
    "\n",
    "The optimal values for these parameters depend on the specific dataset and problem. It is important to carefully tune these parameters using techniques such as cross-validation or grid search to find the best combination for optimal performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00cc597-a4a5-489b-853b-336d38938e81",
   "metadata": {},
   "source": [
    "# Q5. Assignment:\n",
    ".Import the necessary libraries and load the dataset\n",
    "\n",
    ".Split the dataset into training and testing set\n",
    "\n",
    ".Preprocess the data using any technique of your choice (e.g. scaling, normalization)\n",
    "                                                         \n",
    ".Create an instance of the SVC classifier and train it on the training data\n",
    "                                                         \n",
    ".Use the trained classifier to predict the labels of the testing data\n",
    "                                                         \n",
    ".Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy, precision, recall, F1-score\n",
    "                                                                             \n",
    ".Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to improve its performance.\n",
    "                                                                             \n",
    ".Train the tuned classifier on the entire dataset\n",
    "                                                                             \n",
    ".Save the trained classifier to a file for future use.\n",
    "\n",
    "Note: You can use any dataset of your choice for this assignment, but make sure it is suitable for\n",
    "classification and has a sufficient number of features and samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ff8a6c-cc3a-4b00-a713-bfb8101995fa",
   "metadata": {},
   "source": [
    "# Answer 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f052c511-277c-4a89-b5d5-e8f1a523af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2f1c271-b7ee-4fc3-8c9d-eae9b3155a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c460c06b-74bd-426b-8e31-1a6f41095a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the SVC classifier\n",
    "model = SVC()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'poly', 'rbf'],\n",
    "    'gamma': [0.1, 1, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd674ba8-aeeb-473d-bfb1-2a86de7b9249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b1286f3-536a-4459-bd19-bb177fabfd46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.1, gamma=0.1, kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=0.1, gamma=0.1, kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=0.1, gamma=0.1, kernel='poly')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the tuned classifier on the entire dataset\n",
    "tuned_model = grid_search.best_estimator_\n",
    "tuned_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e3bda8c-2c47-4461-ab3f-48ff9206bcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained classifier to a file\n",
    "joblib.dump(tuned_model, 'svm_classifier.pkl')\n",
    "\n",
    "# Predict the labels for the testing data\n",
    "y_pred = tuned_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c15c2174-50e3-4fae-935a-45c594bd2291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e74330-ac13-485b-b3d4-626b4c63ec57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
